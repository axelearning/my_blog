<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/my_blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/my_blog/" rel="alternate" type="text/html" /><updated>2020-04-06T09:58:33+04:00</updated><id>http://localhost:4000/my_blog/feed.xml</id><title type="html">A DATA SCIENCE LEARNING BLOG</title><entry><title type="html">Who are the Most Prolific Players?</title><link href="http://localhost:4000/my_blog/project/2020/03/24/Most_prolific_players.html" rel="alternate" type="text/html" title="Who are the Most Prolific Players?" /><published>2020-03-24T08:00:00+04:00</published><updated>2020-03-24T08:00:00+04:00</updated><id>http://localhost:4000/my_blog/project/2020/03/24/Most_prolific_players</id><content type="html" xml:base="http://localhost:4000/my_blog/project/2020/03/24/Most_prolific_players.html">&lt;p&gt;Today we will speak about one of my favorite hobbies: &lt;strong&gt;Football.&lt;/strong&gt; The purpose of this project is to level up my skills in different fields while I am working on a subject I love. We will start from scratch by collecting our own data and end up by designing a &lt;strong&gt;dashboard&lt;/strong&gt;. The goal is to find the most prolific soccer players on the season 2019-2020. Just bellow, you can find the final result. Underneath the dashboard, We will roll back the process together and discover how we can create this neat interactive visualization.&lt;/p&gt;

&lt;div class=&quot;tableauPlaceholder&quot; id=&quot;viz1585028433847&quot; style=&quot;position: relative&quot;&gt;
	&lt;noscript&gt;
		&lt;a href=&quot;#&quot;&gt;
			&lt;img alt=&quot; &quot; src=&quot;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;So&amp;#47;SoccerprojectV2&amp;#47;Dashboard&amp;#47;1_rss.png&quot; style=&quot;border: none&quot; /&gt;
		&lt;/a&gt;
	&lt;/noscript&gt;
	&lt;object class=&quot;tableauViz&quot; style=&quot;display:none;&quot;&gt;
		&lt;param name=&quot;host_url&quot; value=&quot;https%3A%2F%2Fpublic.tableau.com%2F&quot; /&gt; 
		&lt;param name=&quot;embed_code_version&quot; value=&quot;3&quot; /&gt; 
		&lt;param name=&quot;site_root&quot; value=&quot;&quot; /&gt;\
		&lt;param name=&quot;name&quot; value=&quot;SoccerprojectV2&amp;#47;Dashboard&quot; /&gt;
		&lt;param name=&quot;tabs&quot; value=&quot;no&quot; /&gt;
		&lt;param name=&quot;toolbar&quot; value=&quot;no&quot; /&gt;
		&lt;param name=&quot;static_image&quot; value=&quot;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;So&amp;#47;SoccerprojectV2&amp;#47;Dashboard&amp;#47;1.png&quot; /&gt; 
		&lt;param name=&quot;animate_transition&quot; value=&quot;yes&quot; /&gt;
		&lt;param name=&quot;display_static_image&quot; value=&quot;yes&quot; /&gt;
		&lt;param name=&quot;display_spinner&quot; value=&quot;yes&quot; /&gt;
		&lt;param name=&quot;display_overlay&quot; value=&quot;yes&quot; /&gt;
		&lt;param name=&quot;display_count&quot; value=&quot;yes&quot; /&gt;
	&lt;/object&gt;
&lt;/div&gt;

&lt;script type=&quot;text/javascript&quot;&gt;                    
	var divElement = document.getElementById('viz1585028433847');
	var vizElement = divElement.getElementsByTagName('object')[0];                    
	vizElement.style.width='100%';
	vizElement.style.height=(divElement.offsetWidth*1.05)+'px';                    
	var scriptElement = document.createElement('script');                    
	scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    
	vizElement.parentNode.insertBefore(scriptElement, vizElement);                
&lt;/script&gt;

&lt;h2 id=&quot;what-i-have-learned&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;What I have learned?&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Web Scrapping:&lt;/strong&gt; After playing around with &lt;em&gt;Beautifull Soup&lt;/em&gt; and Se&lt;em&gt;lenium&lt;/em&gt;, I now have in my toolkits the basic skill of dynamic scrapping&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Analysis:&lt;/strong&gt; I have increased my skills in processing messy data into a structured and clean form.  I also gain insight and create new interesting features to improve the visualization&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Visualisation:&lt;/strong&gt; I discover Tableau public and all the cool features of this software.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UNIX command:&lt;/strong&gt; I expanded my skill in the shell while I was creating the automation of the program&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;In this article, I will share with you my experience on this first project. Nevertheless, we will not go too much in code detailed so if you are interested and want to go deeper, you can find all the files of this project on my GitHub page, just right here.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Get the data&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clean and prepared the database&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Design the visualisation&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Leave the loop&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;1-get-the-data&quot;&gt;1. Get the data&lt;/h1&gt;
&lt;p&gt;Welcome guys in the most important part of the project: collecting the data. We need to be careful regarding the source of our data. We can create the most insightful visualization but if we are using crapy data we can not output a valuable product. Data are the fuel of our car, without it, we can’t go anywhere! Even if we have the last Lamborghini, or if we are Lewis Hamilton’s brother.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How to collect data?&lt;/strong&gt;&lt;br /&gt; 
We have multiple choices! First of all, we can &lt;strong&gt;find an existing database.&lt;/strong&gt; It is the easiest way, all the work is done for us. We just need to download the files! However they are sometime hard to find or we often need to pay for it.  If we can’t find any suitable database, or if we are broke, we need to create one by ourselves. That means, we have to gather the data from the web by an &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Application_programming_interface&quot;&gt;API&lt;/a&gt;&lt;/strong&gt;, or by &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Web_scraping&quot;&gt;Web Scraping&lt;/a&gt;.&lt;/strong&gt; API is often easier to use but not all the web site have one. In my case, I decided to collect the data by Web Scraping. I think it is a good starting point to understand web pages syntaxes when you are a beginner.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What I have done?&lt;/strong&gt;&lt;br /&gt; 
I start my project by gathering the 250 players with the best total of goals and assists on the season 2019-2020. I decided to choose the website &lt;a href=&quot;https://www.transfermarkt.com/meisteeinsaetze/topscorer/statistik/2019/art//saison_id/2019/altersklasse//ausrichtung//spielerposition_id/0/land_id/0&quot;&gt;Transfermarkt&lt;/a&gt;. It is one of the largest and reliable sports websites.  In figure 1, we can see the first website page, 25 players with the best totals.  After a while, I find out how to handle dynamic Web Scraping by creating a bot who automatically browses and scrape data through the 10 pages of the website. I finally get the table which stores the 250 players with the best total, see figure 2.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/my_blog/assets/soccer_project/fig1.png&quot; alt=&quot;figure 1&quot; /&gt;
&lt;em&gt;&lt;center&gt;figure 1: the bottom of the 1/10 page for the top scorrer&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/my_blog/assets/soccer_project/fig2.png&quot; alt=&quot;figure 2&quot; /&gt;
&lt;em&gt;&lt;center&gt;figure 2: Output after fetching the data with the first bot, open on Jupyter notebook&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;However, the data I have collected so far are global information for each player. In this second part, we will see how we have collected, detailed results on player. For that, we scrape towards the site &lt;a href=&quot;https://fbref.com/en/&quot;&gt;Fbref&lt;/a&gt;, which contains more detailed data. On this website, we can find as expected goals, minutes played, penalties attempts and so on for each game during the season. For instance, in figure 3, we can see the detailed data of Ciro Immobile during the season 2019-2020.  In this case, the scrapping process is more complicated than the first one. To understand why let’s quickly compare the two bots. The first one just needs to browse through the 10 pages of the site to collect the 250 best players’ info while the second has to search each player personal page, find into it the table with the detailed result on the actual season and collect the data. That process needs to be done for the 250 players, the main problem is that the player’s page is not similar.  To be honest, That was the trickiest part and I was close to bang my head into a wall. However, after a while, I finally found out how to handle the scraping process for each player. We can see the result in figure 4.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/my_blog/assets/soccer_project/fig3.png&quot; alt=&quot;figure 3&quot; /&gt;
&lt;em&gt;&lt;center&gt;figure 3: screenshot of the detailed data in the website Fbref&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/my_blog/assets/soccer_project/fig4.png&quot; alt=&quot;figure 4&quot; /&gt;
&lt;em&gt;&lt;center&gt;figure 4: Final database output after scraping the web with our two bots&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;To sum up, we create our own database with python web scraping libraries to have access to detailed results on the 250 most prolific players of the world. Now, we need to clean and prepared data before visualization - part 2. Then we will explore different visualization on Tableau - part 3. And finally, we need to leave the loop by automating the update of the database  - part 4.  Bellow, I share with you some interesting resource on Web Scrapping:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://towardsdatascience.com/controlling-the-web-with-python-6fceb22c5f08#0da5&quot;&gt;An adventure in simple web automation&lt;/a&gt;,&lt;/strong&gt; a good first lecture to understand how web automation works on python&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=lvFAuUcowT4&amp;amp;t=109s&quot;&gt;Automate TINDER with Python tutorial&lt;/a&gt;,&lt;/strong&gt; a tutorial  video which go through all the process to create a bot&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://medium.com/ymedialabs-innovation/web-scraping-using-beautiful-soup-and-selenium-for-dynamic-page-2f8ad15efe25#5dd0&quot;&gt;An introduction to dynamique Web Scrapping&lt;/a&gt;&lt;/strong&gt; with Selenium and Beautiful Soup&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;2-clean-and-prepared-the-database&quot;&gt;2. Clean and prepared the database&lt;/h1&gt;
&lt;p&gt;The goal of this part is to clean and prepare the data before visualization. Here we will use python data analysis library, called &lt;a href=&quot;https://en.wikipedia.org/wiki/Pandas_(software)&quot;&gt;pandas&lt;/a&gt;, which provides an effective solution to perform data preparation. I mean loading, cleaning, transforming, and rearranging the data. Data preparation might be an annoying task and it is often time-consuming. Therefore, the active and wide community in stack overflow of pandas is a must-have when you begin in data science and you get often stuck. In our case, we proceed with basic tasks such as handling missing data or converting data type. For more detailed take a look at the Jupyter notebook on the GitHub page, detailed_stats/analysis.ipynb, I tried to write annotations during the process.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/my_blog/assets/soccer_project/fig5.png&quot; alt=&quot;figure 5&quot; /&gt;
&lt;em&gt;&lt;center&gt;figure 5: Example of data analysis with pandas on Jupyter Notebook&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;By now we have a clean and basic data frame and we can start exploring the data. I enjoy this part, we start understanding what happened and I feel like Sherlock Holmes.  This part is often called data exploration, we will create visualization for the purpose to gain insights that will sharpen our expectations on our final product. Then when we have a more precise idea of what we want, we can go back to our analysis on python and complete it with new features and so on until we are satisfied with our result.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What I have done?&lt;/strong&gt; &lt;br /&gt; 
In my case, I make the choice to group the game during the season in four buckets: domestic league, Champion league, Europa League and Cup. Thus, it is possible to filter the players by game categories. I also create two new features that describe how a player is effective. These attributes describe the average time in minutes for a player to score and to give an assist.&lt;/p&gt;

&lt;p&gt;For example, in his domestic league, Erling Haaland scored 25 times but he scored on average every 60 minutes. On the other hand, Ciro Immobile scored 27 goals in his domestic league but he had an average time per goal higher of 79 minutes. That means Haaland is a more effective player even if he scored less.&lt;/p&gt;

&lt;p&gt;Finally, we have a decent input for our final visualization! Do not forget this is an iterative process between preparation and visualization. I do not create this analysis in one shot, I create a basic simple analysis. Then, I was growing insight into Tableau by exploring the data. Thus, I was able to have a clear idea of what I want for my Dashboard. I transform that idea into new features by going back on my Jupyter Notebook and so on until I was satisfied with my Dashboard. In the next part, we will see why we bother to handle the visualization part on Tableau instead of simply using python visualization libraries. To go deeper into analysis with python, I recommend the &lt;a href=&quot;https://wesmckinney.com/pages/book.html&quot;&gt;book&lt;/a&gt; of Wes McKinney, a superb resource to get started with pandas and the other data science libraries!&lt;/p&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;3-design-the-visualisation&quot;&gt;3. Design the visualisation&lt;/h1&gt;
&lt;p&gt;Python libraries as matplotlib, seaborn, plotly, and others are very functional and capable of almost any visualization. On the other hand, Tableau is quite easy to use, with a large panel of tools, and gives us wonderful visualization. Moreover, Tableau’s built-in instruments speed the process of complex visualization. For instance, it is effortless to create a map plot or use interactive filters. Tableau is a strong tool when we want to present our results to a client or when the visualization is really important. However, it could be annoying to juggling between Tableau for data visualization and Python. Therefore, if we just create basic visualization for gaining insight from the data we are good with Python.  In some cases, when we need extra customization, we can also hit the limit of Tableau in this case we have to use Python as well.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What I have done?&lt;/strong&gt; &lt;br /&gt; 
In my case, I keep the dashboard simple, with two plots. The one on the top relates the number of goals and assists of the ten best players. The bottom one, “Average time per Goals”, display the ten most effective scorer, I mean players with the best ratio of goals by minutes played. The Dashboard are interactive with two filters.  The first one, give the possibility to play on a range of date and the other to pick the competition type - domestic league, cup, and  European cup. I add some additional information in the tooltip of each plot as well.&lt;/p&gt;

&lt;p&gt;To conclude this part, our beautiful visualization can already be used. However, in some cases such as mine, we will often need to refresh the data. In the next part, we will see how to automate this process and get out of the loop. Bellow some good resource I found regarding Tableau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://public.tableau.com/en-us/s/resources&quot;&gt;Tutorial from Tableau public&lt;/a&gt;,&lt;/strong&gt; learn the basics with Tableau itself&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Lu0jrymqOGM&amp;amp;t=734s&quot;&gt;10 Tableau Dashboard Design Tips&lt;/a&gt;,&lt;/strong&gt; a youtube video to create a clean Dashboard&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=CAZ3IAJEuCI&amp;amp;t=1505s&quot;&gt;Tips and Tricks from a Tableau Jedi&lt;/a&gt;,&lt;/strong&gt; a youtube video with some useful tips&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;4-get-out-of-the-loop&quot;&gt;4. Get out of the loop&lt;/h1&gt;
&lt;p&gt;By now, we scraped the web to create a detailed database of the most prolific players. Then we have cleaned and explored the data for the purpose to create a dashboard on Tableau. By now, we can share on our website our dashboard and start using it like a tool to compare the different players. Nevertheless, if the data are not updated every week dashboard will become useless and non-accurate. As each team plays on average one game per week, players statistics’ will grow every week and the dashboard will be up to date. If we don’t need to update our data as often, we can manually update it. However, this boring task can be updated and we can make better use of our time!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Automate the boring stuff&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As already discuss, our data need to be updated every week. To leave the loop, we will create &lt;a href=&quot;https://en.wikipedia.org/wiki/Daemon_(computing)&quot;&gt;a background process&lt;/a&gt; which run every Monday at 12:30 PM our programs. &lt;strong&gt;I will explained how I handle it on my a MAC computer, it might be different on a different operating system&lt;/strong&gt;.  To do it I used a tool call launchd, a tool for starting, stopping and managing scripts and processes. First  you need to defined the task to proceed in background  on a XML code. You will give a name to our job, specify the task you need to automate, and define a schedule. This XML code are stored as a &lt;code class=&quot;highlighter-rouge&quot;&gt;.plist&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;~/Library/LaunchdAgents&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;plist&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;version=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1.0&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;dict&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;c&quot;&gt;&amp;lt;!--script name--&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;Label&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;string&amp;gt;&lt;/span&gt;soccer.analysis&lt;span class=&quot;nt&quot;&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
    
    		&lt;span class=&quot;c&quot;&gt;&amp;lt;!--script job--&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;ProgramArguments&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;array&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;string&amp;gt;&lt;/span&gt;/Users/axel/opt/anaconda3/bin/python&lt;span class=&quot;nt&quot;&gt;&amp;lt;/string&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!--python path--&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;string&amp;gt;&lt;/span&gt;file/path&lt;span class=&quot;nt&quot;&gt;&amp;lt;/string&amp;gt;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;&amp;lt;!--python file path--&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/array&amp;gt;&lt;/span&gt;
    
       &lt;span class=&quot;c&quot;&gt;&amp;lt;!--run every 3 hours--&amp;gt;&lt;/span&gt;
    	&lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;StartCalendarInterval&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
    	&lt;span class=&quot;nt&quot;&gt;&amp;lt;dict&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;Weekday&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;nt&quot;&gt;&amp;lt;integer&amp;gt;&lt;/span&gt;0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/integer&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;Hour&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;nt&quot;&gt;&amp;lt;integer&amp;gt;&lt;/span&gt;12&lt;span class=&quot;nt&quot;&gt;&amp;lt;/integer&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;Minutes&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
    		&lt;span class=&quot;nt&quot;&gt;&amp;lt;integer&amp;gt;&lt;/span&gt;30&lt;span class=&quot;nt&quot;&gt;&amp;lt;/integer&amp;gt;&lt;/span&gt;		
    	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dict&amp;gt;&lt;/span&gt;
    
        &lt;span class=&quot;c&quot;&gt;&amp;lt;!--collect errors &amp;amp; output--&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;StandardOutPath&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;string&amp;gt;&lt;/span&gt;/tmp/collect.data.covid974.out&lt;span class=&quot;nt&quot;&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;key&amp;gt;&lt;/span&gt;StandardErrorPath&lt;span class=&quot;nt&quot;&gt;&amp;lt;/key&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;string&amp;gt;&lt;/span&gt;/tmp/collect.data.covid974.err&lt;span class=&quot;nt&quot;&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/dict&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plist&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next from the shell we need to load our scripts.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-zhs&quot;&gt;    cd ~/Library/LaunchAgents
    launchdctl load soccer.analysis 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that all our script will run our python in background every morning a 12:30 pm 🥳&lt;/p&gt;

&lt;p&gt;To have better explanation on this topic you might want take a look at this posts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.launchd.info/&quot;&gt;&lt;strong&gt;Launchd documentation&lt;/strong&gt;&lt;/a&gt;, complete and well explain&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.maketecheasier.com/use-launchd-run-scripts-on-schedule-macos/&quot;&gt;&lt;strong&gt;How to Use launchd to Run Scripts on Schedule in macOS&lt;/strong&gt;&lt;/a&gt;, detailed explanation of the process&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;I realised how is it important to work on personal project to level up and sharpen my skills. Moreover, as long as we clearly define what we want to do grammatical language programming are easy to find online - when the community is wide. That why from my perspective, the most important skills are for me computer thinking, and problems solving.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today we will speak about one of my favorite hobbies: Football. The purpose of this project is to level up my skills in different fields while I am working on a subject I love. We will start from scratch by collecting our own data and end up by designing a dashboard. The goal is to find the most prolific soccer players on the season 2019-2020. Just bellow, you can find the final result. Underneath the dashboard, We will roll back the process together and discover how we can create this neat interactive visualization.</summary></entry><entry><title type="html">What does a data scientist?</title><link href="http://localhost:4000/my_blog/what_does_a_datascientist" rel="alternate" type="text/html" title="What does a data scientist?" /><published>2019-10-21T00:00:00+04:00</published><updated>2019-10-21T00:00:00+04:00</updated><id>http://localhost:4000/my_blog/data_science</id><content type="html" xml:base="http://localhost:4000/my_blog/what_does_a_datascientist">&lt;blockquote&gt;
  &lt;p&gt;Data science is a multidisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data - &lt;em&gt;Wikipedia&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The role of a data scientist is to &lt;code class=&quot;highlighter-rouge&quot;&gt;solve real company probleme using data&lt;/code&gt;. For this purpose, a data scientist will need to know how to code, and also have a good understanding of math and algorithms, from those skills he will be able to gain insight from data. Then he is using that insight by making prediction and draw conclusion.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;./assets/datascience.png&quot; /&gt;
  &lt;figcaption&gt;Venn diagram of the skills of a Data scientist - Drew Conway&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;However, he also need to know how to communicate his conclusions to the rest of the team he is working with which are non data scientists. That mean, he will also need to know how to do great data visualization and be a good business communicator.&lt;/p&gt;

&lt;p&gt;Bellow you can follow how does a data scientist proceed to solve problem from scratch:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;understand the problem of the company&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;data collection&lt;/strong&gt;: collect data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;data preparation&lt;/strong&gt;: clean and transformed data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;data exploration&lt;/strong&gt;: converting data into visual insights (data visualization tool, machine learning tools, algorithmes)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;data modeling&lt;/strong&gt;: using ML to create models, training and testing the data, using the best models&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;visualization &amp;amp; communication&lt;/strong&gt;: be able to communicate his results with the rest of the team in a clear way. Need a good data visualization and good skill in communication.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Depend on the company’s size and budget data scientist have a different role into a company. For instance, in a startup with a little funding one data scientist will do the entire work from understanding the problem to the communication of his conclusion and his prediction. In an other hand in a large company with a huge budget, the work will be shared, a software engineer will collect, clean, and transform the data. Meanwhile, a machine learning engineer will analyze the data and find the best models from Machine Learning.&lt;/p&gt;</content><author><name></name></author><summary type="html">Data science is a multidisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data - Wikipedia</summary></entry></feed>